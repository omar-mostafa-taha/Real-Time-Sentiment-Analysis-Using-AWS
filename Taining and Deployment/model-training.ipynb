{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Binary Classification `imdb` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development Environment and Permissions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker>=2.140.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.232.2)\n",
      "Requirement already satisfied: transformers==4.26.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.26.1)\n",
      "Collecting datasets==2.10.1 (from datasets[s3]==2.10.1)\n",
      "  Using cached datasets-2.10.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.26.1) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.26.1) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.26.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.26.1) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.26.1) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.26.1) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.26.1) (2.32.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.26.1) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.26.1) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.10.1->datasets[s3]==2.10.1) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.10.1->datasets[s3]==2.10.1) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.10.1->datasets[s3]==2.10.1) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.10.1->datasets[s3]==2.10.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.10.1->datasets[s3]==2.10.1) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fsspec[http]>=2021.11.1->datasets==2.10.1->datasets[s3]==2.10.1) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.10.1->datasets[s3]==2.10.1) (3.10.9)\n",
      "Requirement already satisfied: responses<0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.10.1->datasets[s3]==2.10.1) (0.18.0)\n",
      "Requirement already satisfied: s3fs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets[s3]==2.10.1) (0.4.2)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (23.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.34.142 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (1.35.17)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (2.2.1)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (7.1.0)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (6.11.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (4.23.0)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (0.3.0)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (4.2.2)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (4.25.4)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (6.0.0)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (1.0.4)\n",
      "Requirement already satisfied: sagemaker-mlflow in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (0.1.0)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (3.0.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.140.0) (2.2.2)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.34.142->sagemaker>=2.140.0) (1.35.17)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.34.142->sagemaker>=2.140.0) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.34.142->sagemaker>=2.140.0) (0.10.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->datasets[s3]==2.10.1) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->datasets[s3]==2.10.1) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->datasets[s3]==2.10.1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->datasets[s3]==2.10.1) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->datasets[s3]==2.10.1) (1.14.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->datasets[s3]==2.10.1) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1) (4.12.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker>=2.140.0) (3.19.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.26.1) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.26.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.26.1) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.26.1) (2024.7.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker>=2.140.0) (2.8.2)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker>=2.140.0) (13.8.1)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker>=2.140.0) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker>=2.140.0) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker>=2.140.0) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker>=2.140.0) (0.19.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-pasta->sagemaker>=2.140.0) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets==2.10.1->datasets[s3]==2.10.1) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets==2.10.1->datasets[s3]==2.10.1) (2024.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker>=2.140.0) (1.7.6.8)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker>=2.140.0) (0.3.4)\n",
      "Requirement already satisfied: mlflow>=2.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-mlflow->sagemaker>=2.140.0) (2.16.2)\n",
      "Requirement already satisfied: mlflow-skinny==2.16.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (2.16.2)\n",
      "Requirement already satisfied: Flask<4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (3.0.3)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (1.13.3)\n",
      "Requirement already satisfied: graphene<4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (3.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (3.9.1)\n",
      "Requirement already satisfied: scikit-learn<2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (1.5.1)\n",
      "Requirement already satisfied: scipy<2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (1.14.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (2.0.35)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (3.1.4)\n",
      "Requirement already satisfied: gunicorn<24 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (23.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (8.1.7)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (0.34.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (3.1.43)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (1.27.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker>=2.140.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker>=2.140.0) (2.20.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker>=2.140.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker>=2.140.0) (2.18.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets==2.10.1->datasets[s3]==2.10.1) (0.2.0)\n",
      "Requirement already satisfied: Mako in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (1.3.5)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (3.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (1.8.2)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (3.2.4)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (3.2.0)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (9.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (2.1.5)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker>=2.140.0) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (10.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (3.1.1)\n",
      "Requirement already satisfied: google-auth~=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (2.35.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (4.0.11)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (0.48b0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker>=2.140.0) (0.6.0)\n",
      "Using cached datasets-2.10.1-py3-none-any.whl (469 kB)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.0.1\n",
      "    Uninstalling datasets-3.0.1:\n",
      "      Successfully uninstalled datasets-3.0.1\n",
      "Successfully installed datasets-2.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sagemaker>=2.140.0\" \"transformers==4.26.1\" \"datasets[s3]==2.10.1\" --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker.huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::798111172440:role/service-role/c134909a3421853l7874054t1w79-SageMakerExecutionRole-N93UPDSTX8TN\n",
      "sagemaker bucket: sagemaker-us-east-1-798111172440\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "We are using the `datasets` library to download and preprocess the `imdb` dataset. After preprocessing, the dataset will be uploaded to our `sagemaker_session_bucket` to be used within our training job. The [imdb](http://ai.stanford.edu/~amaas/data/sentiment/) dataset consists of 25000 training and 25000 testing highly polar movie reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.10.1)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: huggingface_hub in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.25.1)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2024.6.1)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.10.9)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.14.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Using cached datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.10.1\n",
      "    Uninstalling datasets-2.10.1:\n",
      "      Successfully uninstalled datasets-2.10.1\n",
      "Successfully installed datasets-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U datasets huggingface_hub fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer used in preprocessing\n",
    "tokenizer_name = 'distilbert-base-uncased'\n",
    "\n",
    "# dataset used\n",
    "dataset_name = 'stanfordnlp/imdb'\n",
    "\n",
    "# s3 key prefix for the data\n",
    "s3_prefix = 'samples/datasets/imdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba681fbf3bd2493484d9802d57352eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = load_dataset(r'stanfordnlp/imdb', streaming=True)\n",
    "\n",
    "# download tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "# tokenizer helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True)\n",
    "\n",
    "# load dataset\n",
    "train_dataset, test_dataset = load_dataset('imdb', split=['train', 'test'])\n",
    "test_dataset = test_dataset.shuffle().select(range(10000)) # smaller the size for test dataset to 10k \n",
    "\n",
    "\n",
    "# tokenize dataset\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# set format for pytorch\n",
    "train_dataset =  train_dataset.rename_column(\"label\", \"labels\")\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading data to `sagemaker_session_bucket`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/fsspec/registry.py:279: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d881a68a3b340b791d5e4f1e0b2d9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e9b818141d4e61a22158776e8e3fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # save train_dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/train'\n",
    "train_dataset.save_to_disk(training_input_path)\n",
    "\n",
    "# # save test_dataset to s3\n",
    "test_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/test'\n",
    "test_dataset.save_to_disk(test_input_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning & starting Sagemaker Training Job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m accuracy_score, precision_recall_fscore_support\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdatasets\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m load_from_disk\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# hyperparameters sent by the client are passed as command-line arguments to the script.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m3\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--train_batch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m32\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--eval_batch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--warmup_steps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m500\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--learning_rate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[34m5e-5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--output_data_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--n_gpus\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--training_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--test_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TEST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    args, _ = parser.parse_known_args()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Set up logging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    logging.basicConfig(\u001b[37m\u001b[39;49;00m\n",
      "        level=logging.getLevelName(\u001b[33m\"\u001b[39;49;00m\u001b[33mINFO\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        handlers=[logging.StreamHandler(sys.stdout)],\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mformat\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m%(asctime)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(name)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(levelname)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(message)s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# load datasets\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_dataset = load_from_disk(args.training_dir)\u001b[37m\u001b[39;49;00m\n",
      "    test_dataset = load_from_disk(args.test_dir)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m loaded train_dataset length is: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[36mlen\u001b[39;49;00m(train_dataset)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m loaded test_dataset length is: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[36mlen\u001b[39;49;00m(test_dataset)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# compute metrics function for binary classification\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcompute_metrics\u001b[39;49;00m(pred):\u001b[37m\u001b[39;49;00m\n",
      "        labels = pred.label_ids\u001b[37m\u001b[39;49;00m\n",
      "        preds = pred.predictions.argmax(-\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\u001b[33m\"\u001b[39;49;00m\u001b[33mbinary\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        acc = accuracy_score(labels, preds)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m {\u001b[33m\"\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: acc, \u001b[33m\"\u001b[39;49;00m\u001b[33mf1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: f1, \u001b[33m\"\u001b[39;49;00m\u001b[33mprecision\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: precision, \u001b[33m\"\u001b[39;49;00m\u001b[33mrecall\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: recall}\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# download model from model hub\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    model = AutoModelForSequenceClassification.from_pretrained(args.model_name)\u001b[37m\u001b[39;49;00m\n",
      "    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# define training args\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    training_args = TrainingArguments(\u001b[37m\u001b[39;49;00m\n",
      "        output_dir=args.model_dir,\u001b[37m\u001b[39;49;00m\n",
      "        num_train_epochs=args.epochs,\u001b[37m\u001b[39;49;00m\n",
      "        per_device_train_batch_size=args.train_batch_size,\u001b[37m\u001b[39;49;00m\n",
      "        per_device_eval_batch_size=args.eval_batch_size,\u001b[37m\u001b[39;49;00m\n",
      "        warmup_steps=args.warmup_steps,\u001b[37m\u001b[39;49;00m\n",
      "        evaluation_strategy=\u001b[33m\"\u001b[39;49;00m\u001b[33mepoch\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        logging_dir=\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.output_data_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/logs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        learning_rate=\u001b[36mfloat\u001b[39;49;00m(args.learning_rate),\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# create Trainer instance\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    trainer = Trainer(\u001b[37m\u001b[39;49;00m\n",
      "        model=model,\u001b[37m\u001b[39;49;00m\n",
      "        args=training_args,\u001b[37m\u001b[39;49;00m\n",
      "        compute_metrics=compute_metrics,\u001b[37m\u001b[39;49;00m\n",
      "        train_dataset=train_dataset,\u001b[37m\u001b[39;49;00m\n",
      "        eval_dataset=test_dataset,\u001b[37m\u001b[39;49;00m\n",
      "        tokenizer=tokenizer,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# train model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    trainer.train()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# evaluate model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    eval_result = trainer.evaluate(eval_dataset=test_dataset)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# writes eval result to file which can be accessed later in s3 ouput\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(args.output_data_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33meval_results.txt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m writer:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m***** Eval results *****\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m key, value \u001b[35min\u001b[39;49;00m \u001b[36msorted\u001b[39;49;00m(eval_result.items()):\u001b[37m\u001b[39;49;00m\n",
      "            writer.write(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mkey\u001b[33m}\u001b[39;49;00m\u001b[33m = \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mvalue\u001b[33m}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Saves the model to s3\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    trainer.save_model(args.model_dir)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize /home/ec2-user/SageMaker/code/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "sagemaker-notebook.ipynb  train.py\n"
     ]
    }
   ],
   "source": [
    "!ls /home/ec2-user/SageMaker/code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Estimator and start a training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_dir = \"/home/ec2-user/SageMaker/code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'epochs': 1,\n",
    "                 'train_batch_size': 32,\n",
    "                 'model_name':'distilbert-base-uncased'\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(entry_point='train.py',\n",
    "                            source_dir=source_dir,\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            instance_count=1,\n",
    "                            role=role,\n",
    "                            transformers_version='4.26',\n",
    "                            pytorch_version='1.13',\n",
    "                            py_version='py39',\n",
    "                            hyperparameters = hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2024-10-08-16-13-15-443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-08 16:13:21 Starting - Starting the training job\n",
      "2024-10-08 16:13:21 Pending - Training job waiting for capacity......\n",
      "2024-10-08 16:13:59 Pending - Preparing the instances for training...\n",
      "2024-10-08 16:14:47 Downloading - Downloading input data...\n",
      "2024-10-08 16:15:13 Downloading - Downloading the training image........................\n",
      "2024-10-08 16:19:20 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m2024-10-08 16:19:36,337 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-10-08 16:19:36,359 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-10-08 16:19:36,375 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-10-08 16:19:36,378 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-10-08 16:19:37,819 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-10-08 16:19:37,871 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-10-08 16:19:37,922 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-10-08 16:19:37,945 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 1,\n",
      "        \"model_name\": \"distilbert-base-uncased\",\n",
      "        \"train_batch_size\": 32\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2024-10-08-16-13-15-443\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-798111172440/huggingface-pytorch-training-2024-10-08-16-13-15-443/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"train_batch_size\":32}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-798111172440/huggingface-pytorch-training-2024-10-08-16-13-15-443/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"train_batch_size\":32},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"is_smddprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2024-10-08-16-13-15-443\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-798111172440/huggingface-pytorch-training-2024-10-08-16-13-15-443/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--model_name\",\"distilbert-base-uncased\",\"--train_batch_size\",\"32\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=distilbert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 train.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\u001b[0m\n",
      "\u001b[34m2024-10-08 16:19:37,994 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m2024-10-08 16:19:41,084 - __main__ - INFO -  loaded train_dataset length is: 25000\u001b[0m\n",
      "\u001b[34m2024-10-08 16:19:41,084 - __main__ - INFO -  loaded test_dataset length is: 10000\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mThe following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34mThe following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m***** Running training *****\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 25000\u001b[0m\n",
      "\u001b[34mNum examples = 25000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\u001b[0m\n",
      "\u001b[34mGradient Accumulation steps = 1\n",
      "  Total optimization steps = 782\u001b[0m\n",
      "\u001b[34mNum Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 782\u001b[0m\n",
      "\u001b[34mNumber of trainable parameters = 66955010\u001b[0m\n",
      "\u001b[34mNumber of trainable parameters = 66955010\u001b[0m\n",
      "\u001b[34m0%|          | 0/782 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2024-10-08 16:19:45.235 algo-1:59 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-10-08 16:19:45.429 algo-1:59 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-10-08 16:19:45.430 algo-1:59 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-10-08 16:19:45.430 algo-1:59 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-10-08 16:19:45.431 algo-1:59 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-10-08 16:19:45.431 algo-1:59 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mYou're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34mYou're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m0%|          | 1/782 [00:01<18:09,  1.40s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/782 [00:01<10:52,  1.20it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 3/782 [00:02<08:32,  1.52it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 4/782 [00:02<07:26,  1.74it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 5/782 [00:03<06:50,  1.89it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 6/782 [00:03<06:27,  2.00it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 7/782 [00:04<06:13,  2.08it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 8/782 [00:04<06:03,  2.13it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 9/782 [00:04<05:57,  2.16it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 10/782 [00:05<05:53,  2.19it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 11/782 [00:05<05:50,  2.20it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 12/782 [00:06<05:47,  2.21it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 13/782 [00:06<05:45,  2.22it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 14/782 [00:07<05:44,  2.23it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 15/782 [00:07<05:43,  2.23it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 16/782 [00:08<05:42,  2.24it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 17/782 [00:08<05:41,  2.24it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 18/782 [00:08<05:40,  2.24it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 19/782 [00:09<05:40,  2.24it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 20/782 [00:09<05:39,  2.24it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 21/782 [00:10<05:39,  2.24it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 22/782 [00:10<05:38,  2.24it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 23/782 [00:11<05:38,  2.24it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 24/782 [00:11<05:38,  2.24it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 25/782 [00:12<05:37,  2.24it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 26/782 [00:12<05:37,  2.24it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 27/782 [00:12<05:36,  2.24it/s]\u001b[0m\n",
      "\u001b[34m4%|▎         | 28/782 [00:13<05:36,  2.24it/s]\u001b[0m\n",
      "\u001b[34m4%|▎         | 29/782 [00:13<05:35,  2.24it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 30/782 [00:14<05:35,  2.24it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 31/782 [00:14<05:34,  2.25it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 32/782 [00:15<05:34,  2.24it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 33/782 [00:15<05:34,  2.24it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 34/782 [00:16<05:33,  2.24it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 35/782 [00:16<05:34,  2.24it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 36/782 [00:17<05:34,  2.23it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 37/782 [00:17<05:33,  2.23it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 38/782 [00:17<05:32,  2.24it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 39/782 [00:18<05:32,  2.23it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 40/782 [00:18<05:31,  2.24it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 41/782 [00:19<05:30,  2.24it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 42/782 [00:19<05:30,  2.24it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 43/782 [00:20<05:29,  2.24it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 44/782 [00:20<05:29,  2.24it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 45/782 [00:21<05:28,  2.24it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 46/782 [00:21<05:28,  2.24it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 47/782 [00:21<05:27,  2.24it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 48/782 [00:22<05:26,  2.25it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 49/782 [00:22<05:26,  2.24it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 50/782 [00:23<05:26,  2.24it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 51/782 [00:23<05:25,  2.24it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 52/782 [00:24<05:24,  2.25it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 53/782 [00:24<05:24,  2.24it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 54/782 [00:25<05:24,  2.25it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 55/782 [00:25<05:23,  2.25it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 56/782 [00:25<05:23,  2.24it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 57/782 [00:26<05:23,  2.24it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 58/782 [00:26<05:22,  2.24it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 59/782 [00:27<05:22,  2.24it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 60/782 [00:27<05:21,  2.25it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 61/782 [00:28<05:21,  2.24it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 62/782 [00:28<05:21,  2.24it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 63/782 [00:29<05:21,  2.24it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 64/782 [00:29<05:21,  2.24it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 65/782 [00:29<05:20,  2.24it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 66/782 [00:30<05:19,  2.24it/s]\u001b[0m\n",
      "\u001b[34m9%|▊         | 67/782 [00:30<05:19,  2.24it/s]\u001b[0m\n",
      "\u001b[34m9%|▊         | 68/782 [00:31<05:18,  2.24it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 69/782 [00:31<05:18,  2.24it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 70/782 [00:32<05:17,  2.24it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 71/782 [00:32<05:17,  2.24it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 72/782 [00:33<05:16,  2.24it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 73/782 [00:33<05:16,  2.24it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 74/782 [00:33<05:16,  2.24it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 75/782 [00:34<05:15,  2.24it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 76/782 [00:34<05:14,  2.24it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 77/782 [00:35<05:14,  2.24it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 78/782 [00:35<05:14,  2.24it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 79/782 [00:36<05:13,  2.24it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 80/782 [00:36<05:13,  2.24it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 81/782 [00:37<05:12,  2.24it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 82/782 [00:37<05:12,  2.24it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 83/782 [00:37<05:11,  2.24it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 84/782 [00:38<05:11,  2.24it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 85/782 [00:38<05:10,  2.24it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 86/782 [00:39<05:10,  2.24it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 87/782 [00:39<05:10,  2.24it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 88/782 [00:40<05:09,  2.24it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 89/782 [00:40<05:08,  2.24it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 90/782 [00:41<05:08,  2.24it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 91/782 [00:41<05:08,  2.24it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 92/782 [00:41<05:07,  2.24it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 93/782 [00:42<05:07,  2.24it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 94/782 [00:42<05:07,  2.24it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 95/782 [00:43<05:06,  2.24it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 96/782 [00:43<05:06,  2.24it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 97/782 [00:44<05:05,  2.24it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 98/782 [00:44<05:05,  2.24it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 99/782 [00:45<05:04,  2.24it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 100/782 [00:45<05:04,  2.24it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 101/782 [00:46<05:03,  2.24it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 102/782 [00:46<05:03,  2.24it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 103/782 [00:46<05:03,  2.24it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 104/782 [00:47<05:02,  2.24it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 105/782 [00:47<05:02,  2.24it/s]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 106/782 [00:48<05:01,  2.24it/s]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 107/782 [00:48<05:01,  2.24it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 108/782 [00:49<05:01,  2.24it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 109/782 [00:49<05:00,  2.24it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 110/782 [00:50<05:00,  2.24it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 111/782 [00:50<04:59,  2.24it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 112/782 [00:50<04:59,  2.24it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 113/782 [00:51<04:58,  2.24it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 114/782 [00:51<04:58,  2.24it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 115/782 [00:52<04:57,  2.24it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 116/782 [00:52<04:57,  2.24it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 117/782 [00:53<05:02,  2.19it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 118/782 [00:53<05:06,  2.16it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 119/782 [00:54<05:10,  2.13it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 120/782 [00:54<05:15,  2.10it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 121/782 [00:55<05:11,  2.12it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 122/782 [00:55<05:06,  2.15it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 123/782 [00:55<05:02,  2.18it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 124/782 [00:56<04:59,  2.20it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 125/782 [00:56<04:57,  2.21it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 126/782 [00:57<04:55,  2.22it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 127/782 [00:57<04:54,  2.23it/s]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 128/782 [00:58<04:53,  2.23it/s]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 129/782 [00:58<04:52,  2.23it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 130/782 [00:59<04:51,  2.23it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 131/782 [00:59<04:51,  2.23it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 132/782 [01:00<04:50,  2.23it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 133/782 [01:00<04:50,  2.23it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 134/782 [01:00<04:49,  2.23it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 135/782 [01:01<04:49,  2.24it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 136/782 [01:01<04:48,  2.24it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 137/782 [01:02<04:48,  2.24it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 138/782 [01:02<04:48,  2.24it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 139/782 [01:03<04:47,  2.23it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 140/782 [01:03<04:47,  2.23it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 141/782 [01:04<04:46,  2.24it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 142/782 [01:04<04:46,  2.24it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 143/782 [01:04<04:45,  2.23it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 144/782 [01:05<04:45,  2.23it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 145/782 [01:05<04:45,  2.23it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 146/782 [01:06<04:45,  2.23it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 147/782 [01:06<04:44,  2.23it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 148/782 [01:07<04:44,  2.23it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 149/782 [01:07<04:43,  2.23it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 150/782 [01:08<04:43,  2.23it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 151/782 [01:08<04:43,  2.23it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 152/782 [01:08<04:42,  2.23it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 153/782 [01:09<04:42,  2.23it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 154/782 [01:09<04:41,  2.23it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 155/782 [01:10<04:41,  2.23it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 156/782 [01:10<04:40,  2.23it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 157/782 [01:11<04:40,  2.23it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 158/782 [01:11<04:40,  2.23it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 159/782 [01:12<04:39,  2.23it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 160/782 [01:12<04:39,  2.23it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 161/782 [01:13<04:38,  2.23it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 162/782 [01:13<04:37,  2.23it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 163/782 [01:13<04:37,  2.23it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 164/782 [01:14<04:37,  2.23it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 165/782 [01:14<04:36,  2.23it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 166/782 [01:15<04:36,  2.23it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 167/782 [01:15<04:35,  2.23it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 168/782 [01:16<04:35,  2.23it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 169/782 [01:16<04:34,  2.23it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 170/782 [01:17<04:34,  2.23it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 171/782 [01:17<04:34,  2.23it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 172/782 [01:17<04:34,  2.22it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 173/782 [01:18<04:34,  2.22it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 174/782 [01:18<04:33,  2.22it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 175/782 [01:19<04:32,  2.22it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 176/782 [01:19<04:32,  2.23it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 177/782 [01:20<04:31,  2.23it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 178/782 [01:20<04:30,  2.23it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 179/782 [01:21<04:30,  2.23it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 180/782 [01:21<04:29,  2.23it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 181/782 [01:21<04:29,  2.23it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 182/782 [01:22<04:29,  2.23it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 183/782 [01:22<04:28,  2.23it/s]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 184/782 [01:23<04:28,  2.23it/s]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 185/782 [01:23<04:27,  2.23it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 186/782 [01:24<04:27,  2.23it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 187/782 [01:24<04:27,  2.23it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 188/782 [01:25<04:26,  2.23it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 189/782 [01:25<04:26,  2.23it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 190/782 [01:26<04:25,  2.23it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 191/782 [01:26<04:25,  2.23it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 192/782 [01:26<04:24,  2.23it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 193/782 [01:27<04:24,  2.23it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 194/782 [01:27<04:24,  2.23it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 195/782 [01:28<04:23,  2.23it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 196/782 [01:28<04:23,  2.23it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 197/782 [01:29<04:22,  2.23it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 198/782 [01:29<04:22,  2.23it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 199/782 [01:30<04:21,  2.23it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 200/782 [01:30<04:21,  2.23it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 201/782 [01:30<04:20,  2.23it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 202/782 [01:31<04:20,  2.23it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 203/782 [01:31<04:20,  2.23it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 204/782 [01:32<04:19,  2.23it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 205/782 [01:32<04:19,  2.22it/s]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 206/782 [01:33<04:19,  2.22it/s]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 207/782 [01:33<04:18,  2.22it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 208/782 [01:34<04:18,  2.22it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 209/782 [01:34<04:17,  2.22it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 210/782 [01:35<04:17,  2.22it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 211/782 [01:35<04:16,  2.22it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 212/782 [01:35<04:16,  2.22it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 213/782 [01:36<04:15,  2.22it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 214/782 [01:36<04:15,  2.22it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 215/782 [01:37<04:15,  2.22it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 216/782 [01:37<04:14,  2.22it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 217/782 [01:38<04:14,  2.22it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 218/782 [01:38<04:13,  2.22it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 219/782 [01:39<04:13,  2.22it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 220/782 [01:39<04:12,  2.22it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 221/782 [01:39<04:12,  2.23it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 222/782 [01:40<04:11,  2.22it/s]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 223/782 [01:40<04:11,  2.23it/s]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 224/782 [01:41<04:10,  2.22it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 225/782 [01:41<04:10,  2.22it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 226/782 [01:42<04:10,  2.22it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 227/782 [01:42<04:09,  2.22it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 228/782 [01:43<04:09,  2.22it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 229/782 [01:43<04:08,  2.22it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 230/782 [01:44<04:08,  2.22it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 231/782 [01:44<04:07,  2.22it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 232/782 [01:44<04:07,  2.23it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 233/782 [01:45<04:06,  2.23it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 234/782 [01:45<04:06,  2.22it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 235/782 [01:46<04:05,  2.22it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 236/782 [01:46<04:05,  2.22it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 237/782 [01:47<04:04,  2.22it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 238/782 [01:47<04:04,  2.22it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 239/782 [01:48<04:04,  2.22it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 240/782 [01:48<04:03,  2.22it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 241/782 [01:48<04:03,  2.22it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 242/782 [01:49<04:02,  2.22it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 243/782 [01:49<04:02,  2.22it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 244/782 [01:50<04:01,  2.22it/s]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 245/782 [01:50<04:01,  2.22it/s]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 246/782 [01:51<04:01,  2.22it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 247/782 [01:51<04:00,  2.22it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 248/782 [01:52<04:00,  2.22it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 249/782 [01:52<04:00,  2.22it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 250/782 [01:53<03:59,  2.22it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 251/782 [01:53<03:59,  2.22it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 252/782 [01:53<03:58,  2.22it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 253/782 [01:54<03:58,  2.22it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 254/782 [01:54<03:58,  2.22it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 255/782 [01:55<03:58,  2.21it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 256/782 [01:55<03:58,  2.20it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 257/782 [01:56<03:57,  2.21it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 258/782 [01:56<03:56,  2.21it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 259/782 [01:57<03:56,  2.21it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 260/782 [01:57<03:55,  2.22it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 261/782 [01:57<03:54,  2.22it/s]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 262/782 [01:58<03:54,  2.22it/s]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 263/782 [01:58<03:54,  2.22it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 264/782 [01:59<03:53,  2.22it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 265/782 [01:59<03:53,  2.22it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 266/782 [02:00<03:52,  2.22it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 267/782 [02:00<03:52,  2.21it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 268/782 [02:01<03:52,  2.22it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 269/782 [02:01<03:51,  2.21it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 270/782 [02:02<03:51,  2.21it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 271/782 [02:02<03:50,  2.22it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 272/782 [02:02<03:50,  2.22it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 273/782 [02:03<03:50,  2.21it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 274/782 [02:03<03:49,  2.21it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 275/782 [02:04<03:49,  2.21it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 276/782 [02:04<03:48,  2.21it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 277/782 [02:05<03:47,  2.22it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 278/782 [02:05<03:47,  2.22it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 279/782 [02:06<03:46,  2.22it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 280/782 [02:06<03:46,  2.22it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 281/782 [02:07<03:45,  2.22it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 282/782 [02:07<03:45,  2.22it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 283/782 [02:07<03:44,  2.22it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 284/782 [02:08<03:44,  2.22it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 285/782 [02:08<03:43,  2.22it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 286/782 [02:09<03:43,  2.22it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 287/782 [02:09<03:43,  2.22it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 288/782 [02:10<03:42,  2.22it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 289/782 [02:10<03:42,  2.22it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 290/782 [02:11<03:41,  2.22it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 291/782 [02:11<03:41,  2.22it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 292/782 [02:11<03:40,  2.22it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 293/782 [02:12<03:40,  2.22it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 294/782 [02:12<03:40,  2.22it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 295/782 [02:13<03:39,  2.22it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 296/782 [02:13<03:39,  2.22it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 297/782 [02:14<03:38,  2.22it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 298/782 [02:14<03:38,  2.22it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 299/782 [02:15<03:37,  2.22it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 300/782 [02:15<03:37,  2.22it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 301/782 [02:16<03:36,  2.22it/s]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 302/782 [02:16<03:36,  2.22it/s]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 303/782 [02:16<03:36,  2.22it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 304/782 [02:17<03:35,  2.22it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 305/782 [02:17<03:35,  2.22it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 306/782 [02:18<03:34,  2.22it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 307/782 [02:18<03:34,  2.22it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 308/782 [02:19<03:33,  2.22it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 309/782 [02:19<03:33,  2.22it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 310/782 [02:20<03:32,  2.22it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 311/782 [02:20<03:32,  2.22it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 312/782 [02:20<03:31,  2.22it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 313/782 [02:21<03:31,  2.22it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 314/782 [02:21<03:30,  2.22it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 315/782 [02:22<03:30,  2.22it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 316/782 [02:22<03:29,  2.22it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 317/782 [02:23<03:29,  2.22it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 318/782 [02:23<03:29,  2.22it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 319/782 [02:24<03:28,  2.22it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 320/782 [02:24<03:28,  2.22it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 321/782 [02:25<03:27,  2.22it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 322/782 [02:25<03:27,  2.22it/s]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 323/782 [02:25<03:26,  2.22it/s]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 324/782 [02:26<03:26,  2.22it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 325/782 [02:26<03:25,  2.22it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 326/782 [02:27<03:25,  2.22it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 327/782 [02:27<03:24,  2.22it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 328/782 [02:28<03:24,  2.22it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 329/782 [02:28<03:23,  2.22it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 330/782 [02:29<03:23,  2.22it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 331/782 [02:29<03:23,  2.22it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 332/782 [02:29<03:22,  2.22it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 333/782 [02:30<03:22,  2.22it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 334/782 [02:30<03:21,  2.22it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 335/782 [02:31<03:21,  2.22it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 336/782 [02:31<03:20,  2.22it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 337/782 [02:32<03:20,  2.22it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 338/782 [02:32<03:19,  2.22it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 339/782 [02:33<03:19,  2.22it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 340/782 [02:33<03:19,  2.22it/s]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 341/782 [02:34<03:18,  2.22it/s]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 342/782 [02:34<03:18,  2.22it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 343/782 [02:34<03:18,  2.22it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 344/782 [02:35<03:17,  2.22it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 345/782 [02:35<03:17,  2.22it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 346/782 [02:36<03:16,  2.22it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 347/782 [02:36<03:16,  2.22it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 348/782 [02:37<03:15,  2.22it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 349/782 [02:37<03:15,  2.22it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 350/782 [02:38<03:14,  2.22it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 351/782 [02:38<03:13,  2.22it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 352/782 [02:38<03:13,  2.22it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 353/782 [02:39<03:13,  2.22it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 354/782 [02:39<03:12,  2.22it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 355/782 [02:40<03:12,  2.22it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 356/782 [02:40<03:12,  2.21it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 357/782 [02:41<03:11,  2.21it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 358/782 [02:41<03:11,  2.21it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 359/782 [02:42<03:10,  2.22it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 360/782 [02:42<03:10,  2.21it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 361/782 [02:43<03:10,  2.21it/s]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 362/782 [02:43<03:09,  2.21it/s]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 363/782 [02:43<03:09,  2.21it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 364/782 [02:44<03:09,  2.21it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 365/782 [02:44<03:09,  2.21it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 366/782 [02:45<03:08,  2.21it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 367/782 [02:45<03:08,  2.20it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 368/782 [02:46<03:07,  2.20it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 369/782 [02:46<03:07,  2.21it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 370/782 [02:47<03:06,  2.21it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 371/782 [02:47<03:05,  2.21it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 372/782 [02:48<03:05,  2.21it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 373/782 [02:48<03:04,  2.21it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 374/782 [02:48<03:04,  2.21it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 375/782 [02:49<03:03,  2.21it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 376/782 [02:49<03:03,  2.21it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 377/782 [02:50<03:02,  2.21it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 378/782 [02:50<03:02,  2.21it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 379/782 [02:51<03:01,  2.21it/s]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 380/782 [02:51<03:01,  2.21it/s]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 381/782 [02:52<03:01,  2.21it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 382/782 [02:52<03:00,  2.21it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 383/782 [02:53<03:00,  2.21it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 384/782 [02:53<02:59,  2.21it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 385/782 [02:53<02:59,  2.21it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 386/782 [02:54<02:59,  2.21it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 387/782 [02:54<02:58,  2.21it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 388/782 [02:55<02:58,  2.21it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 389/782 [02:55<02:57,  2.21it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 390/782 [02:56<02:57,  2.21it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 391/782 [02:56<02:56,  2.21it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 392/782 [02:57<02:56,  2.21it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 393/782 [02:57<02:55,  2.21it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 394/782 [02:57<02:55,  2.21it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 395/782 [02:58<02:54,  2.21it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 396/782 [02:58<02:54,  2.21it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 397/782 [02:59<02:53,  2.21it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 398/782 [02:59<02:53,  2.21it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 399/782 [03:00<02:53,  2.21it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 400/782 [03:00<02:52,  2.21it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 401/782 [03:01<02:52,  2.21it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 402/782 [03:01<02:51,  2.21it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 403/782 [03:02<02:51,  2.21it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 404/782 [03:02<02:50,  2.21it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 405/782 [03:02<02:50,  2.21it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 406/782 [03:03<02:49,  2.21it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 407/782 [03:03<02:49,  2.21it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 408/782 [03:04<02:48,  2.21it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 409/782 [03:04<02:48,  2.21it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 410/782 [03:05<02:48,  2.21it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 411/782 [03:05<02:47,  2.21it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 412/782 [03:06<02:47,  2.21it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 413/782 [03:06<02:46,  2.21it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 414/782 [03:07<02:46,  2.21it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 415/782 [03:07<02:45,  2.21it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 416/782 [03:07<02:45,  2.21it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 417/782 [03:08<02:45,  2.21it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 418/782 [03:08<02:44,  2.21it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 419/782 [03:09<02:44,  2.21it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 420/782 [03:09<02:43,  2.21it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 421/782 [03:10<02:43,  2.21it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 422/782 [03:10<02:42,  2.21it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 423/782 [03:11<02:42,  2.21it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 424/782 [03:11<02:41,  2.21it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 425/782 [03:11<02:41,  2.22it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 426/782 [03:12<02:40,  2.21it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 427/782 [03:12<02:40,  2.21it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 428/782 [03:13<02:40,  2.21it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 429/782 [03:13<02:39,  2.21it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 430/782 [03:14<02:39,  2.21it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 431/782 [03:14<02:38,  2.21it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 432/782 [03:15<02:38,  2.21it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 433/782 [03:15<02:37,  2.22it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 434/782 [03:16<02:37,  2.22it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 435/782 [03:16<02:37,  2.20it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 436/782 [03:16<02:37,  2.20it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 437/782 [03:17<02:36,  2.20it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 438/782 [03:17<02:36,  2.19it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 439/782 [03:18<02:36,  2.20it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 440/782 [03:18<02:35,  2.20it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 441/782 [03:19<02:35,  2.20it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 442/782 [03:19<02:34,  2.20it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 443/782 [03:20<02:34,  2.20it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 444/782 [03:20<02:33,  2.21it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 445/782 [03:21<02:32,  2.21it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 446/782 [03:21<02:32,  2.21it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 447/782 [03:21<02:31,  2.21it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 448/782 [03:22<02:30,  2.21it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 449/782 [03:22<02:30,  2.21it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 450/782 [03:23<02:30,  2.21it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 451/782 [03:23<02:29,  2.21it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 452/782 [03:24<02:29,  2.21it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 453/782 [03:24<02:28,  2.21it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 454/782 [03:25<02:28,  2.21it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 455/782 [03:25<02:27,  2.21it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 456/782 [03:26<02:27,  2.21it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 457/782 [03:26<02:26,  2.21it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 458/782 [03:26<02:26,  2.22it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 459/782 [03:27<02:26,  2.21it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 460/782 [03:27<02:25,  2.21it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 461/782 [03:28<02:25,  2.21it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 462/782 [03:28<02:24,  2.21it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 463/782 [03:29<02:24,  2.21it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 464/782 [03:29<02:24,  2.21it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 465/782 [03:30<02:23,  2.21it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 466/782 [03:30<02:22,  2.21it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 467/782 [03:31<02:22,  2.21it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 468/782 [03:31<02:22,  2.21it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 469/782 [03:31<02:21,  2.21it/s]\u001b[0m\n",
      "\u001b[34m60%|██████    | 470/782 [03:32<02:21,  2.21it/s]\u001b[0m\n",
      "\u001b[34m60%|██████    | 471/782 [03:32<02:20,  2.21it/s]\u001b[0m\n",
      "\u001b[34m60%|██████    | 472/782 [03:33<02:20,  2.21it/s]\u001b[0m\n",
      "\u001b[34m60%|██████    | 473/782 [03:33<02:19,  2.21it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 474/782 [03:34<02:19,  2.21it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 475/782 [03:34<02:18,  2.21it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 476/782 [03:35<02:18,  2.21it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 477/782 [03:35<02:17,  2.21it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 478/782 [03:35<02:17,  2.21it/s]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 479/782 [03:36<02:16,  2.21it/s]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 480/782 [03:36<02:16,  2.22it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 481/782 [03:37<02:15,  2.22it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 482/782 [03:37<02:15,  2.21it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 483/782 [03:38<02:15,  2.21it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 484/782 [03:38<02:14,  2.21it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 485/782 [03:39<02:14,  2.21it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 486/782 [03:39<02:14,  2.21it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 487/782 [03:40<02:13,  2.21it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 488/782 [03:40<02:12,  2.21it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 489/782 [03:40<02:12,  2.21it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 490/782 [03:41<02:11,  2.21it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 491/782 [03:41<02:11,  2.21it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 492/782 [03:42<02:11,  2.21it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 493/782 [03:42<02:10,  2.21it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 494/782 [03:43<02:09,  2.22it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 495/782 [03:43<02:09,  2.22it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 496/782 [03:44<02:09,  2.22it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 497/782 [03:44<02:08,  2.21it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 498/782 [03:45<02:08,  2.21it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 499/782 [03:45<02:07,  2.22it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 500/782 [03:45<02:07,  2.21it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.363, 'learning_rate': 5e-05, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 500/782 [03:45<02:07,  2.21it/s]\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-500\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-500\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-500/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-500/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-500/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-500/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-500/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-500/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-500/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-500/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 501/782 [03:47<03:50,  1.22it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 502/782 [03:48<03:18,  1.41it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 503/782 [03:48<02:56,  1.58it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 504/782 [03:48<02:40,  1.73it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 505/782 [03:49<02:29,  1.85it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 506/782 [03:49<02:21,  1.94it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 507/782 [03:50<02:16,  2.02it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 508/782 [03:50<02:12,  2.08it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 509/782 [03:51<02:08,  2.12it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 510/782 [03:51<02:06,  2.14it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 511/782 [03:52<02:05,  2.17it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 512/782 [03:52<02:03,  2.18it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 513/782 [03:53<02:02,  2.19it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 514/782 [03:53<02:02,  2.20it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 515/782 [03:53<02:01,  2.20it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 516/782 [03:54<02:00,  2.20it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 517/782 [03:54<01:59,  2.21it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 518/782 [03:55<01:59,  2.21it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 519/782 [03:55<01:58,  2.21it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 520/782 [03:56<01:58,  2.21it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 521/782 [03:56<01:57,  2.21it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 522/782 [03:57<01:57,  2.22it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 523/782 [03:57<01:56,  2.22it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 524/782 [03:57<01:56,  2.22it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 525/782 [03:58<01:55,  2.22it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 526/782 [03:58<01:55,  2.22it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 527/782 [03:59<01:54,  2.22it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 528/782 [03:59<01:54,  2.22it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 529/782 [04:00<01:54,  2.22it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 530/782 [04:00<01:53,  2.22it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 531/782 [04:01<01:53,  2.21it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 532/782 [04:01<01:53,  2.21it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 533/782 [04:02<01:52,  2.21it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 534/782 [04:02<01:51,  2.22it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 535/782 [04:02<01:51,  2.21it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 536/782 [04:03<01:51,  2.21it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 537/782 [04:03<01:50,  2.22it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 538/782 [04:04<01:50,  2.22it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 539/782 [04:04<01:49,  2.22it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 540/782 [04:05<01:49,  2.22it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 541/782 [04:05<01:48,  2.21it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 542/782 [04:06<01:48,  2.21it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 543/782 [04:06<01:47,  2.22it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 544/782 [04:07<01:47,  2.22it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 545/782 [04:07<01:46,  2.22it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 546/782 [04:07<01:46,  2.22it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 547/782 [04:08<01:46,  2.22it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 548/782 [04:08<01:45,  2.21it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 549/782 [04:09<01:45,  2.21it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 550/782 [04:09<01:44,  2.21it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 551/782 [04:10<01:44,  2.21it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 552/782 [04:10<01:43,  2.21it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 553/782 [04:11<01:43,  2.21it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 554/782 [04:11<01:43,  2.21it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 555/782 [04:11<01:42,  2.21it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 556/782 [04:12<01:42,  2.21it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 557/782 [04:12<01:41,  2.21it/s]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 558/782 [04:13<01:41,  2.22it/s]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 559/782 [04:13<01:40,  2.22it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 560/782 [04:14<01:40,  2.22it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 561/782 [04:14<01:39,  2.22it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 562/782 [04:15<01:39,  2.22it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 563/782 [04:15<01:38,  2.22it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 564/782 [04:16<01:38,  2.22it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 565/782 [04:16<01:38,  2.21it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 566/782 [04:16<01:38,  2.20it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 567/782 [04:17<01:37,  2.20it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 568/782 [04:17<01:36,  2.21it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 569/782 [04:18<01:36,  2.21it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 570/782 [04:18<01:35,  2.21it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 571/782 [04:19<01:35,  2.22it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 572/782 [04:19<01:34,  2.22it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 573/782 [04:20<01:34,  2.22it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 574/782 [04:20<01:33,  2.22it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 575/782 [04:21<01:33,  2.22it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 576/782 [04:21<01:32,  2.22it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 577/782 [04:21<01:32,  2.22it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 578/782 [04:22<01:31,  2.22it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 579/782 [04:22<01:31,  2.22it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 580/782 [04:23<01:30,  2.23it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 581/782 [04:23<01:30,  2.22it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 582/782 [04:24<01:30,  2.22it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 583/782 [04:24<01:29,  2.22it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 584/782 [04:25<01:29,  2.22it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 585/782 [04:25<01:28,  2.22it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 586/782 [04:25<01:28,  2.22it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 587/782 [04:26<01:27,  2.22it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 588/782 [04:26<01:27,  2.22it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 589/782 [04:27<01:26,  2.22it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 590/782 [04:27<01:26,  2.22it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 591/782 [04:28<01:25,  2.22it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 592/782 [04:28<01:25,  2.22it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 593/782 [04:29<01:25,  2.22it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 594/782 [04:29<01:24,  2.22it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 595/782 [04:30<01:24,  2.22it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 596/782 [04:30<01:23,  2.22it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 597/782 [04:30<01:23,  2.22it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 598/782 [04:31<01:22,  2.22it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 599/782 [04:31<01:22,  2.22it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 600/782 [04:32<01:21,  2.22it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 601/782 [04:32<01:21,  2.22it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 602/782 [04:33<01:20,  2.22it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 603/782 [04:33<01:20,  2.23it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 604/782 [04:34<01:19,  2.23it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 605/782 [04:34<01:19,  2.23it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 606/782 [04:34<01:18,  2.23it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 607/782 [04:35<01:18,  2.23it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 608/782 [04:35<01:18,  2.23it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 609/782 [04:36<01:17,  2.23it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 610/782 [04:36<01:17,  2.23it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 611/782 [04:37<01:16,  2.23it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 612/782 [04:37<01:16,  2.23it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 613/782 [04:38<01:15,  2.23it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 614/782 [04:38<01:15,  2.23it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 615/782 [04:38<01:14,  2.23it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 616/782 [04:39<01:14,  2.23it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 617/782 [04:39<01:13,  2.23it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 618/782 [04:40<01:13,  2.23it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 619/782 [04:40<01:12,  2.23it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 620/782 [04:41<01:12,  2.23it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 621/782 [04:41<01:12,  2.23it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 622/782 [04:42<01:11,  2.23it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 623/782 [04:42<01:11,  2.23it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 624/782 [04:43<01:10,  2.23it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 625/782 [04:43<01:10,  2.23it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 626/782 [04:43<01:09,  2.23it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 627/782 [04:44<01:09,  2.23it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 628/782 [04:44<01:08,  2.23it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 629/782 [04:45<01:08,  2.23it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 630/782 [04:45<01:08,  2.23it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 631/782 [04:46<01:07,  2.23it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 632/782 [04:46<01:07,  2.23it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 633/782 [04:47<01:06,  2.23it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 634/782 [04:47<01:06,  2.23it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 635/782 [04:47<01:05,  2.23it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 636/782 [04:48<01:05,  2.23it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 637/782 [04:48<01:04,  2.23it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 638/782 [04:49<01:04,  2.23it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 639/782 [04:49<01:04,  2.23it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 640/782 [04:50<01:03,  2.23it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 641/782 [04:50<01:03,  2.23it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 642/782 [04:51<01:02,  2.23it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 643/782 [04:51<01:02,  2.23it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 644/782 [04:51<01:01,  2.23it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 645/782 [04:52<01:01,  2.23it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 646/782 [04:52<01:00,  2.23it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 647/782 [04:53<01:00,  2.23it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 648/782 [04:53<01:00,  2.23it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 649/782 [04:54<00:59,  2.23it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 650/782 [04:54<00:59,  2.23it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 651/782 [04:55<00:58,  2.23it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 652/782 [04:55<00:58,  2.23it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 653/782 [04:56<00:57,  2.23it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 654/782 [04:56<00:57,  2.24it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 655/782 [04:56<00:56,  2.24it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 656/782 [04:57<00:56,  2.23it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 657/782 [04:57<00:55,  2.23it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 658/782 [04:58<00:55,  2.23it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 659/782 [04:58<00:55,  2.24it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 660/782 [04:59<00:54,  2.23it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 661/782 [04:59<00:54,  2.24it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 662/782 [05:00<00:53,  2.24it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 663/782 [05:00<00:53,  2.24it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 664/782 [05:00<00:52,  2.24it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 665/782 [05:01<00:52,  2.24it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 666/782 [05:01<00:51,  2.24it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 667/782 [05:02<00:51,  2.24it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 668/782 [05:02<00:50,  2.24it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 669/782 [05:03<00:50,  2.24it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 670/782 [05:03<00:50,  2.24it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 671/782 [05:04<00:49,  2.24it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 672/782 [05:04<00:49,  2.24it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 673/782 [05:04<00:48,  2.24it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 674/782 [05:05<00:48,  2.24it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 675/782 [05:05<00:47,  2.24it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 676/782 [05:06<00:47,  2.24it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 677/782 [05:06<00:46,  2.24it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 678/782 [05:07<00:46,  2.24it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 679/782 [05:07<00:46,  2.24it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 680/782 [05:08<00:45,  2.24it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 681/782 [05:08<00:45,  2.24it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 682/782 [05:08<00:44,  2.24it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 683/782 [05:09<00:44,  2.24it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 684/782 [05:09<00:43,  2.24it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 685/782 [05:10<00:43,  2.24it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 686/782 [05:10<00:42,  2.24it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 687/782 [05:11<00:42,  2.24it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 688/782 [05:11<00:42,  2.24it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 689/782 [05:12<00:41,  2.24it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 690/782 [05:12<00:41,  2.24it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 691/782 [05:12<00:40,  2.24it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 692/782 [05:13<00:40,  2.23it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 693/782 [05:13<00:39,  2.24it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 694/782 [05:14<00:39,  2.24it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 695/782 [05:14<00:38,  2.24it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 696/782 [05:15<00:38,  2.24it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 697/782 [05:15<00:38,  2.24it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 698/782 [05:16<00:37,  2.24it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 699/782 [05:16<00:37,  2.22it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 700/782 [05:17<00:36,  2.22it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 701/782 [05:17<00:36,  2.23it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 702/782 [05:17<00:35,  2.22it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 703/782 [05:18<00:35,  2.23it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 704/782 [05:18<00:34,  2.23it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 705/782 [05:19<00:34,  2.23it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 706/782 [05:19<00:33,  2.24it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 707/782 [05:20<00:33,  2.24it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 708/782 [05:20<00:33,  2.24it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 709/782 [05:21<00:32,  2.24it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 710/782 [05:21<00:32,  2.24it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 711/782 [05:21<00:31,  2.24it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 712/782 [05:22<00:31,  2.24it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 713/782 [05:22<00:30,  2.24it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 714/782 [05:23<00:30,  2.24it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 715/782 [05:23<00:29,  2.24it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 716/782 [05:24<00:29,  2.24it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 717/782 [05:24<00:29,  2.24it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 718/782 [05:25<00:28,  2.24it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 719/782 [05:25<00:28,  2.24it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 720/782 [05:25<00:27,  2.24it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 721/782 [05:26<00:27,  2.24it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 722/782 [05:26<00:26,  2.24it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 723/782 [05:27<00:26,  2.24it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 724/782 [05:27<00:25,  2.24it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 725/782 [05:28<00:25,  2.24it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 726/782 [05:28<00:25,  2.24it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 727/782 [05:29<00:24,  2.24it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 728/782 [05:29<00:24,  2.24it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 729/782 [05:30<00:23,  2.24it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 730/782 [05:30<00:23,  2.23it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 731/782 [05:30<00:22,  2.24it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 732/782 [05:31<00:22,  2.24it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 733/782 [05:31<00:21,  2.24it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 734/782 [05:32<00:21,  2.23it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 735/782 [05:32<00:21,  2.24it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 736/782 [05:33<00:20,  2.24it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 737/782 [05:33<00:20,  2.24it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 738/782 [05:34<00:19,  2.24it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 739/782 [05:34<00:19,  2.24it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 740/782 [05:34<00:18,  2.24it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 741/782 [05:35<00:18,  2.24it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 742/782 [05:35<00:17,  2.24it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 743/782 [05:36<00:17,  2.24it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 744/782 [05:36<00:16,  2.24it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 745/782 [05:37<00:16,  2.24it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 746/782 [05:37<00:16,  2.24it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 747/782 [05:38<00:15,  2.24it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 748/782 [05:38<00:15,  2.24it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 749/782 [05:38<00:14,  2.24it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 750/782 [05:39<00:14,  2.24it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 751/782 [05:39<00:13,  2.24it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 752/782 [05:40<00:13,  2.24it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 753/782 [05:40<00:12,  2.24it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 754/782 [05:41<00:12,  2.24it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 755/782 [05:41<00:12,  2.24it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 756/782 [05:42<00:11,  2.24it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 757/782 [05:42<00:11,  2.24it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 758/782 [05:42<00:10,  2.24it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 759/782 [05:43<00:10,  2.24it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 760/782 [05:43<00:09,  2.24it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 761/782 [05:44<00:09,  2.24it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 762/782 [05:44<00:08,  2.24it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 763/782 [05:45<00:08,  2.24it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 764/782 [05:45<00:08,  2.24it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 765/782 [05:46<00:07,  2.24it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 766/782 [05:46<00:07,  2.24it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 767/782 [05:46<00:06,  2.24it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 768/782 [05:47<00:06,  2.24it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 769/782 [05:47<00:05,  2.24it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 770/782 [05:48<00:05,  2.24it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 771/782 [05:48<00:04,  2.24it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 772/782 [05:49<00:04,  2.23it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 773/782 [05:49<00:04,  2.24it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 774/782 [05:50<00:03,  2.24it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 775/782 [05:50<00:03,  2.24it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 776/782 [05:51<00:02,  2.24it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 777/782 [05:51<00:02,  2.24it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 778/782 [05:51<00:01,  2.24it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 779/782 [05:52<00:01,  2.24it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 780/782 [05:52<00:00,  2.24it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 781/782 [05:53<00:00,  2.24it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 782/782 [05:53<00:00,  2.84it/s]\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 10000\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34mNum examples = 10000\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m0%|          | 0/157 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m1%|▏         | 2/157 [00:00<00:22,  6.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m2%|▏         | 3/157 [00:00<00:31,  4.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m3%|▎         | 4/157 [00:00<00:36,  4.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m3%|▎         | 5/157 [00:01<00:38,  3.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m4%|▍         | 6/157 [00:01<00:40,  3.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m4%|▍         | 7/157 [00:01<00:40,  3.67it/s]#033[A\u001b[0m\n",
      "\u001b[34m5%|▌         | 8/157 [00:02<00:41,  3.61it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 9/157 [00:02<00:41,  3.56it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▋         | 10/157 [00:02<00:41,  3.53it/s]#033[A\u001b[0m\n",
      "\u001b[34m7%|▋         | 11/157 [00:02<00:41,  3.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 12/157 [00:03<00:41,  3.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 13/157 [00:03<00:41,  3.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m9%|▉         | 14/157 [00:03<00:40,  3.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 15/157 [00:04<00:40,  3.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m10%|█         | 16/157 [00:04<00:40,  3.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m11%|█         | 17/157 [00:04<00:40,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m11%|█▏        | 18/157 [00:04<00:40,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 19/157 [00:05<00:39,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m13%|█▎        | 20/157 [00:05<00:39,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m13%|█▎        | 21/157 [00:05<00:39,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 22/157 [00:06<00:38,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▍        | 23/157 [00:06<00:38,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▌        | 24/157 [00:06<00:38,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m16%|█▌        | 25/157 [00:06<00:38,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 26/157 [00:07<00:37,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 27/157 [00:07<00:37,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m18%|█▊        | 28/157 [00:07<00:37,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m18%|█▊        | 29/157 [00:08<00:36,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 30/157 [00:08<00:36,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m20%|█▉        | 31/157 [00:08<00:36,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m20%|██        | 32/157 [00:08<00:35,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m21%|██        | 33/157 [00:09<00:35,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 34/157 [00:09<00:35,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 35/157 [00:09<00:35,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m23%|██▎       | 36/157 [00:10<00:34,  3.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m24%|██▎       | 37/157 [00:10<00:34,  3.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m24%|██▍       | 38/157 [00:10<00:34,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▍       | 39/157 [00:10<00:33,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 40/157 [00:11<00:33,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m26%|██▌       | 41/157 [00:11<00:33,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m27%|██▋       | 42/157 [00:11<00:33,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m27%|██▋       | 43/157 [00:12<00:32,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 44/157 [00:12<00:32,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 45/157 [00:12<00:32,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▉       | 46/157 [00:12<00:31,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m30%|██▉       | 47/157 [00:13<00:31,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 48/157 [00:13<00:31,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 49/157 [00:13<00:31,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m32%|███▏      | 50/157 [00:14<00:30,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m32%|███▏      | 51/157 [00:14<00:30,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 52/157 [00:14<00:30,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m34%|███▍      | 53/157 [00:14<00:29,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m34%|███▍      | 54/157 [00:15<00:29,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m35%|███▌      | 55/157 [00:15<00:29,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 56/157 [00:15<00:29,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▋      | 57/157 [00:16<00:28,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 58/157 [00:16<00:28,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m38%|███▊      | 59/157 [00:16<00:28,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m38%|███▊      | 60/157 [00:16<00:27,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 61/157 [00:17<00:27,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 62/157 [00:17<00:27,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m40%|████      | 63/157 [00:17<00:27,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m41%|████      | 64/157 [00:18<00:26,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m41%|████▏     | 65/157 [00:18<00:26,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 66/157 [00:18<00:26,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 67/157 [00:19<00:25,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 68/157 [00:19<00:25,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 69/157 [00:19<00:25,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m45%|████▍     | 70/157 [00:19<00:25,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m45%|████▌     | 71/157 [00:20<00:24,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m46%|████▌     | 72/157 [00:20<00:24,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m46%|████▋     | 73/157 [00:20<00:24,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 74/157 [00:21<00:23,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m48%|████▊     | 75/157 [00:21<00:23,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m48%|████▊     | 76/157 [00:21<00:23,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m49%|████▉     | 77/157 [00:21<00:23,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m50%|████▉     | 78/157 [00:22<00:22,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 79/157 [00:22<00:22,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m51%|█████     | 80/157 [00:22<00:22,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 81/157 [00:23<00:21,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 82/157 [00:23<00:21,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 83/157 [00:23<00:21,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 84/157 [00:23<00:21,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 85/157 [00:24<00:20,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 86/157 [00:24<00:20,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 87/157 [00:24<00:20,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 88/157 [00:25<00:19,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 89/157 [00:25<00:19,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 90/157 [00:25<00:19,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 91/157 [00:25<00:19,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 92/157 [00:26<00:18,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 93/157 [00:26<00:18,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 94/157 [00:26<00:18,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 95/157 [00:27<00:17,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 96/157 [00:27<00:17,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 97/157 [00:27<00:17,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 98/157 [00:27<00:17,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 99/157 [00:28<00:16,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 100/157 [00:28<00:16,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 101/157 [00:28<00:16,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 102/157 [00:29<00:15,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 103/157 [00:29<00:15,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 104/157 [00:29<00:15,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 105/157 [00:29<00:15,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 106/157 [00:30<00:14,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 107/157 [00:30<00:14,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 108/157 [00:30<00:14,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 109/157 [00:31<00:13,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m70%|███████   | 110/157 [00:31<00:13,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████   | 111/157 [00:31<00:13,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 112/157 [00:31<00:12,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 113/157 [00:32<00:12,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 114/157 [00:32<00:12,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 115/157 [00:32<00:12,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 116/157 [00:33<00:11,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 117/157 [00:33<00:11,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 118/157 [00:33<00:11,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 119/157 [00:34<00:10,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 120/157 [00:34<00:10,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 121/157 [00:34<00:10,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 122/157 [00:34<00:10,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 123/157 [00:35<00:09,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 124/157 [00:35<00:09,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 125/157 [00:35<00:09,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m80%|████████  | 126/157 [00:36<00:08,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 127/157 [00:36<00:08,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 128/157 [00:36<00:08,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 129/157 [00:36<00:08,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 130/157 [00:37<00:07,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 131/157 [00:37<00:07,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 132/157 [00:37<00:07,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 133/157 [00:38<00:06,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 134/157 [00:38<00:06,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 135/157 [00:38<00:06,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 136/157 [00:38<00:06,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 137/157 [00:39<00:05,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 138/157 [00:39<00:05,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 139/157 [00:39<00:05,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 140/157 [00:40<00:04,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 141/157 [00:40<00:04,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m90%|█████████ | 142/157 [00:40<00:04,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m91%|█████████ | 143/157 [00:40<00:04,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 144/157 [00:41<00:03,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 145/157 [00:41<00:03,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 146/157 [00:41<00:03,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 147/157 [00:42<00:02,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 148/157 [00:42<00:02,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 149/157 [00:42<00:02,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 150/157 [00:42<00:02,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 151/157 [00:43<00:01,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 152/157 [00:43<00:01,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 153/157 [00:43<00:01,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 154/157 [00:44<00:00,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 155/157 [00:44<00:00,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 156/157 [00:44<00:00,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.1934618204832077, 'eval_accuracy': 0.9253, 'eval_f1': 0.9251277939260298, 'eval_precision': 0.935346574787191, 'eval_recall': 0.9151298830061472, 'eval_runtime': 45.0759, 'eval_samples_per_second': 221.848, 'eval_steps_per_second': 3.483, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 782/782 [06:38<00:00,  2.84it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 157/157 [00:44<00:00,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                                 #033[A\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m{'train_runtime': 398.45, 'train_samples_per_second': 62.743, 'train_steps_per_second': 1.963, 'train_loss': 0.31819575278045575, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 782/782 [06:38<00:00,  2.84it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 782/782 [06:38<00:00,  1.96it/s]\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 10000\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34mNum examples = 10000\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m0%|          | 0/157 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 2/157 [00:00<00:22,  6.92it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 3/157 [00:00<00:31,  4.88it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 4/157 [00:00<00:36,  4.23it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 5/157 [00:01<00:38,  3.92it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 6/157 [00:01<00:40,  3.75it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 7/157 [00:01<00:41,  3.65it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 8/157 [00:02<00:41,  3.59it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 9/157 [00:02<00:41,  3.54it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 10/157 [00:02<00:41,  3.51it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 11/157 [00:02<00:41,  3.50it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 12/157 [00:03<00:41,  3.48it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 13/157 [00:03<00:41,  3.47it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 14/157 [00:03<00:41,  3.46it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 15/157 [00:04<00:41,  3.46it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 16/157 [00:04<00:40,  3.45it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 17/157 [00:04<00:40,  3.45it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 18/157 [00:04<00:40,  3.45it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 19/157 [00:05<00:40,  3.45it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 20/157 [00:05<00:39,  3.45it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 21/157 [00:05<00:39,  3.45it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 22/157 [00:06<00:39,  3.45it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 23/157 [00:06<00:38,  3.45it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 24/157 [00:06<00:38,  3.45it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 25/157 [00:06<00:38,  3.46it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 26/157 [00:07<00:37,  3.46it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 27/157 [00:07<00:37,  3.46it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 28/157 [00:07<00:37,  3.46it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 29/157 [00:08<00:37,  3.46it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 30/157 [00:08<00:36,  3.46it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 31/157 [00:08<00:36,  3.45it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 32/157 [00:08<00:36,  3.45it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 33/157 [00:09<00:35,  3.45it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 34/157 [00:09<00:35,  3.45it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 35/157 [00:09<00:35,  3.45it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 36/157 [00:10<00:35,  3.45it/s]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 37/157 [00:10<00:34,  3.45it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 38/157 [00:10<00:34,  3.45it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 39/157 [00:11<00:34,  3.45it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 40/157 [00:11<00:33,  3.45it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 41/157 [00:11<00:33,  3.45it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 42/157 [00:11<00:33,  3.45it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 43/157 [00:12<00:33,  3.45it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 44/157 [00:12<00:32,  3.45it/s]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 45/157 [00:12<00:32,  3.45it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 46/157 [00:13<00:32,  3.45it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 47/157 [00:13<00:31,  3.45it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 48/157 [00:13<00:31,  3.45it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 49/157 [00:13<00:31,  3.45it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 50/157 [00:14<00:31,  3.45it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 51/157 [00:14<00:30,  3.45it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 52/157 [00:14<00:30,  3.45it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 53/157 [00:15<00:30,  3.45it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 54/157 [00:15<00:29,  3.45it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 55/157 [00:15<00:29,  3.45it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 56/157 [00:15<00:29,  3.45it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 57/157 [00:16<00:29,  3.45it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 58/157 [00:16<00:28,  3.45it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 59/157 [00:16<00:28,  3.45it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 60/157 [00:17<00:28,  3.45it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 61/157 [00:17<00:27,  3.45it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 62/157 [00:17<00:27,  3.45it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 63/157 [00:17<00:27,  3.45it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 64/157 [00:18<00:26,  3.45it/s]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 65/157 [00:18<00:26,  3.45it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 66/157 [00:18<00:26,  3.45it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 67/157 [00:19<00:26,  3.45it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 68/157 [00:19<00:25,  3.45it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 69/157 [00:19<00:25,  3.45it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 70/157 [00:19<00:25,  3.45it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 71/157 [00:20<00:24,  3.45it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 72/157 [00:20<00:24,  3.45it/s]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 73/157 [00:20<00:24,  3.44it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 74/157 [00:21<00:24,  3.44it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 75/157 [00:21<00:23,  3.44it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 76/157 [00:21<00:23,  3.44it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 77/157 [00:22<00:23,  3.44it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 78/157 [00:22<00:22,  3.44it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 79/157 [00:22<00:22,  3.45it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 80/157 [00:22<00:22,  3.44it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 81/157 [00:23<00:22,  3.45it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 82/157 [00:23<00:21,  3.45it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 83/157 [00:23<00:21,  3.44it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 84/157 [00:24<00:21,  3.45it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 85/157 [00:24<00:20,  3.45it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 86/157 [00:24<00:20,  3.45it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 87/157 [00:24<00:20,  3.44it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 88/157 [00:25<00:20,  3.45it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 89/157 [00:25<00:19,  3.44it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 90/157 [00:25<00:19,  3.44it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 91/157 [00:26<00:19,  3.44it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 92/157 [00:26<00:18,  3.44it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 93/157 [00:26<00:18,  3.45it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 94/157 [00:26<00:18,  3.44it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 95/157 [00:27<00:18,  3.44it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 96/157 [00:27<00:17,  3.44it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 97/157 [00:27<00:17,  3.44it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 98/157 [00:28<00:17,  3.44it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 99/157 [00:28<00:16,  3.44it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 100/157 [00:28<00:16,  3.44it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 101/157 [00:29<00:16,  3.44it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 102/157 [00:29<00:15,  3.44it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 103/157 [00:29<00:15,  3.44it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 104/157 [00:29<00:15,  3.44it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 105/157 [00:30<00:15,  3.44it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 106/157 [00:30<00:14,  3.44it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 107/157 [00:30<00:14,  3.44it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 108/157 [00:31<00:14,  3.44it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 109/157 [00:31<00:13,  3.44it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 110/157 [00:31<00:13,  3.44it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 111/157 [00:31<00:13,  3.44it/s]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 112/157 [00:32<00:13,  3.44it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 113/157 [00:32<00:12,  3.44it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 114/157 [00:32<00:12,  3.44it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 115/157 [00:33<00:12,  3.44it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 116/157 [00:33<00:11,  3.44it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 117/157 [00:33<00:11,  3.44it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 118/157 [00:33<00:11,  3.44it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 119/157 [00:34<00:11,  3.44it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 120/157 [00:34<00:10,  3.44it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 121/157 [00:34<00:10,  3.44it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 122/157 [00:35<00:10,  3.44it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 123/157 [00:35<00:09,  3.44it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 124/157 [00:35<00:09,  3.44it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 125/157 [00:35<00:09,  3.44it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 126/157 [00:36<00:09,  3.44it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 127/157 [00:36<00:08,  3.44it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 128/157 [00:36<00:08,  3.44it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 129/157 [00:37<00:08,  3.44it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 130/157 [00:37<00:07,  3.44it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 131/157 [00:37<00:07,  3.44it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 132/157 [00:38<00:07,  3.44it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 133/157 [00:38<00:06,  3.44it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 134/157 [00:38<00:06,  3.44it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 135/157 [00:38<00:06,  3.43it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 136/157 [00:39<00:06,  3.43it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 137/157 [00:39<00:05,  3.43it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 138/157 [00:39<00:05,  3.43it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 139/157 [00:40<00:05,  3.42it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 140/157 [00:40<00:04,  3.43it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 141/157 [00:40<00:04,  3.43it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 142/157 [00:40<00:04,  3.43it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 143/157 [00:41<00:04,  3.43it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 144/157 [00:41<00:03,  3.43it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 145/157 [00:41<00:03,  3.44it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 146/157 [00:42<00:03,  3.44it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 147/157 [00:42<00:02,  3.44it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 148/157 [00:42<00:02,  3.44it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 149/157 [00:42<00:02,  3.44it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 150/157 [00:43<00:02,  3.44it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 151/157 [00:43<00:01,  3.44it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 152/157 [00:43<00:01,  3.44it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 153/157 [00:44<00:01,  3.44it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 154/157 [00:44<00:00,  3.44it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 155/157 [00:44<00:00,  3.44it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 156/157 [00:45<00:00,  3.43it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 157/157 [00:45<00:00,  3.48it/s]\u001b[0m\n",
      "\u001b[34m***** Eval results *****\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m2024-10-08 16:27:10,036 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-10-08 16:27:10,036 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-10-08 16:27:10,036 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-10-08 16:27:12 Uploading - Uploading generated training model\n",
      "2024-10-08 16:27:45 Completed - Training job completed\n",
      "Training seconds: 778\n",
      "Billable seconds: 778\n"
     ]
    }
   ],
   "source": [
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit({'train': training_input_path, 'test': test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-training-2024-10-08-16-52-26-483\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-training-2024-10-08-16-52-26-483\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-training-2024-10-08-16-52-26-483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_estimator.deploy(1, \"ml.g4dn.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9186965227127075}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_input= {\"inputs\":\"I hate using the new Inference DLC.\"}\n",
    "\n",
    "predictor.predict(sentiment_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: huggingface-pytorch-training-2024-10-08-16-52-26-483\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: huggingface-pytorch-training-2024-10-08-16-52-26-483\n",
      "INFO:sagemaker:Deleting endpoint with name: huggingface-pytorch-training-2024-10-08-16-52-26-483\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
